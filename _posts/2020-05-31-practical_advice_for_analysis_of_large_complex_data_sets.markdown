---
layout: post
title: 크고 복잡한 데이터셋 분석을 위한 실무 지침
date: 2020-05-31 00:00:00
author: Patrick Riley
categories: Data-Science
---  
  
  
**Patrick Riley의 [*Practical advice for analysis of large, complex data sets*](http://www.unofficialgoogledatascience.com/2016/10/practical-advice-for-analysis-of-large.html)을 번역했습니다.**
  
  
- - -

  나는 Google 검색 로그에 관한 데이터 과학 팀을 몇 년 간 이끌었다. 우리 팀은 복잡한 결과에 대해 이유를 찾고, 행동 로그를 통해 새로운 현상을 관측하고, 다른 사람이 수행한 분석을 검증하고, 사용자 행동에 대한 지표를 해석해달라는 요청을 종종 받았다. 어떤 팀원들은 수준 높은 데이터 분석을 쉽고 능숙하게 해냈다. 이런 엔지니어와 분석가들은 흔히 "주의 깊고" "꼼꼼하다고" 이야기된다. 이 형용사는 실제로 무얼 의미할까? 이 수식어를 얻으려면 어떤 행동을 해야할까?
  
  이 질문에 대한 대답을 문서로 정리한 뒤 '좋은 데이터 분석'이라는 낙천적이고 단순한 제목으로 Google 사내에 공유했다. 놀랍게도 이 문서는 내가 지난 11 년 동안 Google에서 수행한 그 어떤 일보다 더 많은 사람들이 관심을 갖고 읽었다. 주요 내용을 업데이트한 지 4년이 지났음에도 확인할 때마다 문서를 열어 본 Google 직원 숫자가 상당수로 기록되었다.

  왜 많은 이들이 그 긴 시간 동안 이 문서를 공유해왔을까? 가장 큰 이유를 꼽자면, 문서 내용이 추상적이고 이상적인 것에 대한 것이 아니라 실천 가능하고 구체적인 것으로 알차게 구성되어 있기 때문일 것이다. 나는 본 문서를 통해 많은 엔지니어와 분석가가 좋은 습관을 받아들여 수준 높은 작업을 수행하게 된 것을 보았다. 그래서 지금 이 블로그 게시물를 통해 해당 문서의 내용을 공유하고 싶다.
  
  지침은 크게 세 가지 영역으로 나누었다.
  * *기술적인 영역*: 데이터를 조작하고 검증하는 방법에 대한 아이디어와 기술.
  * *절차적인 영역*: 어떻게 데이터에 접근할지, 스스로 대답해야할 질문은 무엇인지, 확인해야할 내용은 무엇인지에 대한 안내.
  * *사회적인 영역*: 다른 사람과 협력하고 데이터와 인사이트에 대해 의사소통하는 방법.
    
![그림1](https://aldente0630.github.io/assets/practical_advice_for_analysis_of_large_complex_data_sets1.png)
  
# 기술적인 영역
  
### 분포를 눈으로 확인하라
  
  분포를 이야기할 때 요약 지표(평균, 중앙값, 표준 편차 등)를 주로 사용하지만 분포의 모습을 더욱 자세히 확인해 봐야한다. 히스토그램, CDF, Q-Q 플롯 등과 같은 방법을 사용하면 분포가 다봉(multi-modal) 형태인지, 요약 방법론을 결정할 때 특히 중요한 이상치 계층이 존재하는지 등의 중요하고 흥미로운 데이터 특성을 확인할 수 있다.
  
### 이상치를 고려하라

  데이터의 이상치를 살펴 봐야한다. 이상치는 분석에서 더 근본적인 문제에 대한 탄광 속 카나리아 역할을 하곤 한다. 데이터에서 제외시키거나 “특이” 범주로 묶어버려도 괜찮지만 데이터가 해당 범주에 속해야 하는 이유는 알아야한다. 예를 들어 클릭률이 가장 낮은 검색어를 살펴보면 사용자 인터페이스 특정 요소에 대한 클릭이 제대로 집계되지 못한  채 빠져 있음을 알게 될 수 있다. 클릭률이 가장 높은 검색어를 살펴보면 계산하지 말아야할 클릭이 포함되고 있음을 알게 될 수 있다. 반면 일부 이상치는 제대로 설명하기 어려우므로 시간을 너무 소모하지 않게 주의하자.
  
### 잡음의 정도/신뢰도를 보고하라

  무엇보다도 무작위성이 존재하며 이것이 우리를 속일 수 있음을 알아야한다. 조심하지 않으면 잡음 안에서 패턴을 찾았다고 생각할 수 있다. 산출한 모든 추정량에 대해서 그에 맞는 신뢰도를 함께 제시해야 한다. 경우에 따라 이 절차를 공식적이고 엄격하게 적용할 수 있고(추정량의 신뢰 구간, 결론에 대한 p-값 또는 베이즈 인자 같은 기법을 통해) 느슨하게 적용할 수도 있다. 예를 들어 팀 동료가 월요일마다 개구리에 대한 검색이 몇 건 있는지 묻는다면 월요일 과거 며칠치에 대해 빠르게 분석해보고 “그냥 숫자가 아닌 1 천에서 1천 2백만 사이”라고 이야기해줄 수 있다.
  
### 관측치들을 살펴보라

  새로운 분석 코드를 만들 때마다 기존 데이터의 관측치들을 살펴보고 당신이 짠 코드가 그것들을 어떻게 해석하는지 확인해야한다. 이러한 작업 없이 실제로 동작하는 분석 코드를 만드는 것은 코드의 복잡도를 떠나 거의 불가능하다. 분석 작업은 기존 데이터를 잘 요약하여 표현하기 위해 많은 특성들을 제거한다. 복잡도를 갖는 다양한 관측치들을 보다보면 요약한 내용이 일리 있음을 확신할 수 있다.

  빈도가 가장 높은 경우만 치우쳐 보지 않도록 층화 추출 기법으로 값 분포에 대한 좋은 표본들을 얻을 수 있다.

  예를 들어 클릭 시간을 계산하는 경우 분포 전체, 특히 극단값의 관측치를 살펴보라. 데이터를 살펴볼 수 있는 도구/시각화 방법이 없는 경우 먼저 그것들부터 준비해야 한다.
  
### 데이터를 조각으로 나눠라

  데이터를 조각으로 나눈다는 건 데이터를 여러 하위 집단으로 나눈 다음 각 집단의 지표를 살펴보는 걸 의미한다. 보통 웹 트래픽을 분석할 때 모바일 대 데스크톱, 브라우저, 로케일 등 몇가지 기준에 따라 데이터를 쪼갠다. 각 하위 집단마다 기저 현상이 다르게 나타나는 경우 데이터를 조각으로 나눠서 따로 봐야한다. 데이터를 쪼개느 작업이 꼭 필요하지 않아도 여러 조각들을 살펴보며 일관성을 확인하다보면 올바르게 분석하고 있다는 확신이 든다. 경우에 따라 특정 조각에 잘못된 데이터가 있거나 지금까지의 경험과 맞지 않거나 근본적으로 다른 형태가 존재할 수 있다.

  두 집단을 비교하기 위해 데이터를 쪼갤 때(실험/대조군 뿐만 아니라 A 시간대, B 시간대 비교할 경우에도) 혼합 비율 변화에 신경써야 한다. 혼합 비율의 변화란 비교하려는 집단에 따라 데이터 조각의 크기가 서로 다른 경우이다. [심슨의 역설](https://en.wikipedia.org/wiki/Simpson%27s_paradox)을 포함해 여러 혼선이 발생할 수 있다. 일반적으로 두 집단의 데이터 조각 크기가 동일하면 안전하게 비교, 분석할 수 있다.
  
### 실질적으로 중요한지 생각하라

  대량의 데이터를 다루다보면 통계적 유의성에만 초점을 두거나 데이터의 모든 세부 사항을 파악하려는 마음이 생길 수 있다. 그럴 때 스스로 물어봐야 한다. “X값이 Y값보다 0.1% 높다는게 사실이어도 이게 중요할까?” 데이터 일부를 이해/범주화할 수 없는 경우 이러한 질문은 매우 중요하다. Google 로그 중 일부 사용자 에이전트의 문자열을 이해할 수 없는 경우 그게 10%인지 0.1%인지에 따라 해당 사례를 조사하는 비용은 크게 달라진다.

  반대로 종종 소량의 데이터만 가지고 있을 때가 있다. 상당한 지표 차이가 통계적으로 유의하지 않을 수 있지만 “중립”이라고 주장하는 것과는 또 다르다. 스스로 물어보자. “상당한 지표 차이가 실제로 존재할 가능성은 얼마나 될까?”
  
### 시간의 흐름에 따라 일관성을 점검하라

  데이터를 조각으로 나눌 때 거의 항상 사용하는 방식 중 하나는 시간 단위 분할이다.(보통 일자 기준으로 적용하지만 다른 시간 단위도 유용할 수 있다.) 이는 시간의 흐름에 따라 시스템을 운영해나갈 때 기저 데이터에 여러 교란이 발생하기 때문이다. 기능 초기 버전 또는 데이터 초기 수집은 보통 주의 깊게 검사하지만 시간의 흐름에 따라 문제가 발생하는 경우 또한 드물지 않다.

  이상치로 보이는 특정 일자 데이터를 그냥 폐기하라는 뜻이 아니다. 폐기하기 전 해당 데이터를 매개로 하여 특정 일자가 다르게 나타난 이유를 찾아라.

  일자 단위의 데이터를 보면서 얻을 수 있는 또 다른 장점은 데이터의 일별 움직임을 알게되면서 신뢰 구간 혹은 통계적 유의성에 대한 이야기까지 해볼 수 있다는 점이다. 이는 보통 엄격하게 계산된 신뢰 구간을 대체할 순 없지만 변동폭이 클 때 일별 추세 그래프를 통해 그것이 통계적으로 유의미한지 대략 알 수 있다.
  
  # 절차적인 영역
