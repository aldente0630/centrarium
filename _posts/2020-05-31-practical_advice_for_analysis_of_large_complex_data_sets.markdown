---
layout: post
title: 크고 복잡한 데이터셋 분석을 위한 실무 지침
date: 2020-05-31 00:00:00
author: Patrick Riley
categories: Data-Science
---  
  
  
**Patrick Riley의 [*Practical advice for analysis of large, complex data sets*](http://www.unofficialgoogledatascience.com/2016/10/practical-advice-for-analysis-of-large.html)을 번역했습니다.**
  
  
- - -

  나는 Google 검색 로그에 관한 데이터 과학 팀을 몇 년 간 이끌었다. 우리 팀은 복잡한 결과에 대해 이유를 찾고, 행동 로그를 통해 새로운 현상을 관측하고, 다른 사람이 수행한 분석을 검증하고, 사용자 행동에 대한 지표를 해석해달라는 요청을 종종 받았다. 어떤 팀원들은 수준 높은 데이터 분석을 쉽고 능숙하게 해냈다. 이런 엔지니어와 분석가들은 흔히 "주의 깊고" "꼼꼼하다고" 이야기된다. 이 형용사는 실제로 무얼 의미할까? 이 수식어를 얻으려면 어떤 행동을 해야할까?
  
  이 질문에 대한 대답을 문서로 정리한 뒤 '좋은 데이터 분석'이라는 낙천적이고 단순한 제목으로 Google 사내에 공유했다. 놀랍게도 이 문서는 내가 지난 11 년 동안 Google에서 수행한 그 어떤 일보다 더 많은 사람들이 관심을 갖고 읽었다. 주요 내용을 업데이트한 지 4년이 지났음에도 확인할 때마다 문서를 열어 본 Google 직원 숫자가 상당수로 기록되었다.

  왜 많은 이들이 그 긴 시간 동안 이 문서를 공유해왔을까? 가장 큰 이유를 꼽자면, 문서 내용이 추상적이고 이상적인 것에 대한 것이 아니라 실천 가능하고 구체적인 것으로 알차게 구성되어 있기 때문일 것이다. 나는 본 문서를 통해 많은 엔지니어와 분석가가 좋은 습관을 받아들여 수준 높은 작업을 수행하게 된 것을 보았다. 그래서 지금 이 블로그 게시물를 통해 해당 문서의 내용을 공유하고 싶다.
  
  지침은 크게 세 가지 영역으로 나누었다.
  * *기술적인 영역*: 데이터를 조작하고 검증하는 방법에 대한 아이디어와 기술.
  * *절차적인 영역*: 어떻게 데이터에 접근할지, 스스로 대답해야할 질문은 무엇인지, 확인해야할 내용은 무엇인지에 대한 안내.
  * *사회적인 영역*: 다른 사람과 협력하고 데이터와 인사이트에 대해 의사소통하는 방법.
    
![그림1](https://aldente0630.github.io/assets/practical_advice_for_analysis_of_large_complex_data_sets1.png)
  
# 기술적인 영역
  
### 분포를 눈으로 확인하라
  
  분포를 이야기할 때 요약 지표(평균, 중앙값, 표준 편차 등)를 주로 사용하지만 분포의 모습을 더욱 자세히 확인해 봐야한다. 히스토그램, CDF, Q-Q 플롯 등과 같은 방법을 사용하면 분포가 다봉(multi-modal) 형태인지, 요약 방법론을 결정할 때 특히 중요한 이상치 계층이 존재하는지 등의 중요하고 흥미로운 데이터 특성을 확인할 수 있다.
  
### 이상치를 고려하라

  데이터의 이상치를 살펴 봐야한다. 이상치는 분석에서 더 근본적인 문제에 대한 탄광 속 카나리아 역할을 하곤 한다. 데이터에서 제외시키거나 “특이” 범주로 묶어버려도 괜찮지만 데이터가 해당 범주에 속해야 하는 이유는 알아야한다. 예를 들어 클릭률이 가장 낮은 검색어를 살펴보면 사용자 인터페이스 특정 요소에 대한 클릭이 제대로 집계되지 못한  채 빠져 있음을 알게 될 수 있다. 클릭률이 가장 높은 검색어를 살펴보면 계산하지 말아야할 클릭이 포함되고 있음을 알게 될 수 있다. 반면 일부 이상치는 제대로 설명하기 어려우므로 시간을 너무 소모하지 않게 주의하자.
  
### 잡음의 정도/신뢰도를 보고하라

  무엇보다도 무작위성이 존재하며 이것이 우리를 속일 수 있음을 알아야한다. 조심하지 않으면 잡음 안에서 패턴을 찾았다고 생각할 수 있다. 산출한 모든 추정량에 대해서 그에 맞는 신뢰도를 함께 제시해야 한다. 경우에 따라 이 절차를 공식적이고 엄격하게 적용할 수 있고(추정량의 신뢰 구간, 결론에 대한 p-값 또는 베이즈 요인 분석 같은 기법을 통해) 느슨하게 적용할 수도 있다. 예를 들어 팀 동료가 월요일마다 개구리에 대한 검색이 몇 건 있는지 묻는다면 월요일 과거 며칠치에 대해 빠르게 분석해보고 “그냥 숫자가 아닌 1 천에서 1천 2백만 사이”라고 이야기해줄 수 있다.
  
### 관측치들을 살펴보라

  새로운 분석 코드를 만들 때마다 기존 데이터의 관측치들을 살펴보고 당신이 짠 코드가 그것들을 어떻게 해석하는지 확인해야한다. 이러한 작업 없이 실제로 동작하는 분석 코드를 만드는 것은 코드의 복잡도를 떠나 거의 불가능하다. 분석 작업은 기존 데이터를 잘 요약하여 표현하기 위해 많은 특성들을 제거한다. 복잡도를 갖는 다양한 관측치들을 보다보면 요약한 내용이 일리 있음을 확신할 수 있다.

  빈도가 가장 높은 경우만 치우쳐 보지 않도록 층화 추출 기법으로 값 분포에 대한 좋은 표본들을 얻을 수 있다.

  예를 들어 클릭 시간을 계산하는 경우 분포 전체, 특히 극단값의 관측치를 살펴보라. 데이터를 살펴볼 수 있는 도구/시각화 방법이 없는 경우 먼저 그것들부터 준비해야 한다.
  
### 데이터를 조각으로 나눠라

  데이터를 조각으로 나눈다는 건 데이터를 여러 하위 집단으로 나눈 다음 각 집단의 지표를 살펴보는 걸 의미한다. 보통 웹 트래픽을 분석할 때 모바일 대 데스크톱, 브라우저, 로케일 등 몇가지 기준에 따라 데이터를 쪼갠다. 각 하위 집단마다 기저 현상이 다르게 나타나는 경우 데이터를 조각으로 나눠서 따로 봐야한다. 데이터를 쪼개느 작업이 꼭 필요하지 않아도 여러 조각들을 살펴보며 일관성을 확인하다보면 올바르게 분석하고 있다는 확신이 든다. 경우에 따라 특정 조각에 잘못된 데이터가 있거나 지금까지의 경험과 맞지 않거나 근본적으로 다른 형태가 존재할 수 있다.

  두 집단을 비교하기 위해 데이터를 쪼갤 때(실험/대조군 뿐만 아니라 A 시간대, B 시간대 비교할 경우에도) 혼합 비율 변화에 신경써야 한다. 혼합 비율의 변화란 비교하려는 집단에 따라 데이터 조각의 크기가 서로 다른 경우이다. [심슨의 역설](https://en.wikipedia.org/wiki/Simpson%27s_paradox)을 포함해 여러 혼선이 발생할 수 있다. 일반적으로 두 집단의 데이터 조각 크기가 동일하면 안전하게 비교, 분석할 수 있다.
  
### 실질적으로 중요한지 생각하라

  대량의 데이터를 다루다보면 통계적 유의성에만 초점을 두거나 데이터의 모든 세부 사항을 파악하려는 마음이 생길 수 있다. 그럴 때 스스로 물어봐야 한다. “X값이 Y값보다 0.1% 높다는게 사실이어도 이게 중요할까?” 데이터 일부를 이해/범주화할 수 없는 경우 이러한 질문은 매우 중요하다. Google 로그 중 일부 사용자 에이전트의 문자열을 이해할 수 없는 경우 그게 10%인지 0.1%인지에 따라 해당 사례를 조사하는 비용은 크게 달라진다.

  반대로 종종 소량의 데이터만 가지고 있을 때가 있다. 상당한 지표 차이가 통계적으로 유의하지 않을 수 있지만 “중립”이라고 주장하는 것과는 또 다르다. 스스로 물어보자. “상당한 지표 차이가 실제로 존재할 가능성은 얼마나 될까?”
  
### 시간의 흐름에 따라 일관성을 점검하라

  데이터를 조각으로 나눌 때 거의 항상 사용하는 방식 중 하나는 시간 단위 분할이다.(보통 일자 기준으로 적용하지만 다른 시간 단위도 유용할 수 있다.) 이는 시간의 흐름에 따라 시스템을 운영해나갈 때 기저 데이터에 여러 교란이 발생하기 때문이다. 기능 초기 버전 또는 데이터 초기 수집은 보통 주의 깊게 검사하지만 시간의 흐름에 따라 문제가 발생하는 경우 또한 드물지 않다.

  이상치로 보이는 특정 일자 데이터를 그냥 폐기하라는 뜻이 아니다. 폐기하기 전 해당 데이터를 매개로 하여 특정 일자가 다르게 나타난 이유를 찾아라.

  일자 단위의 데이터를 보면서 얻을 수 있는 또 다른 장점은 데이터의 일별 움직임을 알게되면서 신뢰 구간 혹은 통계적 유의성에 대한 이야기까지 해볼 수 있다는 점이다. 이는 보통 엄격하게 계산된 신뢰 구간을 대체할 순 없지만 변동폭이 클 때 일별 추세 그래프를 통해 그것이 통계적으로 유의미한지 대략 알 수 있다.
  
# 절차적인 영역

### 별도의 검증과 설명 그리고 평가

  탐색적 데이터 분석에는 서로 연관된 3 단계가 있다고 생각한다.
1. *검증 또는 [데이터 초기 분석](https://en.wikipedia.org/wiki/Data_analysis)*: 데이터가 균질하고 올바르게 수집됐으며 데이터가 내가 생각한 대로 형태를 갖추고 있는가? 이는 종종 “새너티 확인”라는 이름으로 불린다. 예를 들어 어떤 기능에 대해 수동 테스트를 수행한 경우 해당 테스트의 로그를 봐보자. 모바일을 위한 기능임에도 로그에는 데스크톱으로 기록되지 않았나?
2. *설명*: 데이터에 대한 객관적인 해석은 무엇인가? 예를 들어 “사용자는 일곱 단어로 된 검색어를 더 적게 질의하는가?”, “(클릭 시) 클릭한 페이지를 불러오는 시간이 1% 더 길다”와 “적은 비중의 사용자만이 다음 페이지 결과로 이동한다.” 등이다.
3. *평가*: 주어진 설명을 통해 사용자, Google 또는 세상이 더 나아질거라고 데이터가 이야기하는가? 예를 들어 ‘사용자가 더 빨리 결과를 찾는다’ 또는 ‘클릭 품질이 향상된다’ 등이다.
  
  단계를 이렇게 구분지으면 타인의 동의를 보다 쉽게 구할 수 있다. 설명은 데이터를 통해 모든 사람이 동의할 수 있는 것이어야 한다. 평가는 데이터에 의미와 가치를 부여하기 때문에 훨씬 더 논쟁의 소지가 있다. 설명과 평가를 구분짓지 않으면 데이터를 보고 싶은대로 해석할 가능성이 크다. 일반적으로 평가의 경우 다른 기능과 지표 간의 엄격한 비교를 통해 지표 기준 값 설정에 상당한 시간을 소요하기 때문에 훨씬 더 까다롭다.

  윗 단계들은 차례대로 진행될 수 없다. 데이터를 탐색하며 앞뒤 단계로 이동할 수 있지만 현재 어느 단계에 있는지는 분명히 해야한다.

### 실험/데이터 수집 설정을 확인하라

  데이터를 살펴보기 전에 실험과 데이터 수집 설정을 이해해야한다. 실험을 수행하는 사람과 분석하는 사람 간의 정확한 의사소통은 어려운 점 중 하나이다. 실험 프로토콜 또는 구성을 직접 살펴볼 수 있다면 그렇게 해야한다. 만약 그렇게 할 수 없다면 설정에 대해 본인이 이해한 바를 적어보고 데이터 생성을 담당하는 사람에게 그게 맞는지 확인해야한다.

  비정상적이거나 잘못된 구성 또는 모수에 대한 제한(예: 특정 브라우저에만 유효한 데이터)이 존재할 수 있다. 여기서 발견한 중요한 사실들은 나중에 생각을 정립하고 확인해볼 때 도움이 될 수 있다. 다음은 고려해야할 사항이다.
* 제품의 기능은 직접 사용해봐라. 직접 사용해볼 수 없다면 적어도 스크린 샷/사용자 행동 설명서를 살펴봐라.
* 실험이 수행된 기간 동안 특별한 사건(휴일, 대규모 출시 등)이 있었는지 확인해라.

### 데이터의 생체 신호를 확인하라

  정말 궁금한 질문에 답하기 전에(예: “새롭게 만든 우리 멋진 기능을 사용했는가?”) 관심있는 내용과는 관련 없지만 나중에 분석에 유용하거나 데이터에 존재하는 문제를 알려주는 여러 사항들을 먼저 확인해봐야한다. 사용자 수가 변했는가? 영향을 받은 검색어가 각 하위 그룹마다 올바른 숫자로 나타났는가? 오류 비율이 변했는가? 검진할 때 의사가 항상 키, 몸무게와 혈압을 확인하는 것처럼 잠재적인 문제를 파악하기 위해 데이터의 생체 신호를 늘 확인하라.  
  이는 “검증” 단계에서 가장 중요한 부분이다.

### 표준 작업이 우선, 맞춤 작업은 나중에

  이건 변경하지 말아야할 사항을 확인하라는 이야기와 다소 비슷하다. 신규 기능과 데이터를 살펴보다보면 해당 기능에 대해 새로운 지표를 특별히 만들어, 바꿔 측정하고 싶은 마음이 생긴다. 그러나 곧 변경할 것으로 예상하더라도 표준 지표를 항상 먼저 살펴봐야한다. 예를 들어 신규 UI 기능을 검색 페이지에 추가할 때 해당 UI 기능에 대해 지표를 특별히 만들어 측정하기 전에 결과에 대한 클릭처럼 표준 지표에 미치는 영향을 먼저 이해해야한다. 이렇게 하는 이유는 표준 지표가 훨씬 더 검증된 값이고 정확하기 때문이다. 새롭게 맞춤으로 만든 지표값이 표준 지표 값과 논리적으로 맞지 않는다면 새 맞춤 지표가 잘못 만들어졌을 수 있다.

### 두 번 이상 측정하라

특히 새로운 현상을 포착하려는 경우 동일한 기본 사항을 여러 가지 방법으로 측정하십시오. 그런 다음 이러한 여러 측정 값이 일치하는지 확인하십시오. 여러 측정을 사용하면 측정 또는 로깅 코드의 버그, 기본 데이터의 예기치 않은 기능 또는 중요한 필터링 단계를 식별 할 수 있습니다. 측정에 다른 데이터 소스를 사용할 수 있으면 더 좋습니다.

### 재현성을 확인하라

시간 경과에 따른 슬라이싱 및 일관성은 재현성을 검사하는 특별한 예입니다. 현상이 중요하고 의미가있는 경우 다른 사용자 모집단과 시간에 걸쳐 발생해야합니다. 그러나 재현성은 이것 이상의 것을 의미합니다. 데이터 모델을 작성하는 경우 해당 모델이 기본 데이터의 작은 섭동에 안정적이기를 원합니다. 다른 시간 범위 또는 데이터의 임의의 하위 샘플을 사용하면이 모델이 얼마나 신뢰할 수 있고 재현 가능한지 알 수 있습니다. 재현 할 수없는 경우이 데이터를 생성 한 기본 프로세스에 대한 근본적인 정보를 캡처하지 않았을 수 있습니다.

### 과거 측정과의 일관성을 확인하라

종종 과거에 계산 된 것과 유사한 메트릭을 계산하게됩니다. 이러한 측정 값이 다른 사용자 모집단에 있더라도 메트릭을 과거에보고 된 메트릭과 비교해야합니다. 예를 들어, 특정 모집단의 검색 량을 측정 할 때 일반적으로 허용되는 수보다 훨씬 많은 수를 측정하는 경우 조사해야합니다. 귀하의 전화 번호는이 인구에 맞을 수도 있지만 이제는이를 검증하기 위해 더 많은 노력을 기울여야합니다. 같은 것을 측정하고 있습니까? 이 인구가 다르다고 믿을만한 합리적인 이유가 있습니까? 정확한 동의를 얻을 필요는 없지만 동일한 구장에 있어야합니다. 그렇지 않은 경우 자신을 완전히 확신 할 수있을 때까지 자신이 잘못되었다고 가정하십시오. 가장 놀라운 데이터는 멋진 새로운 통찰력이 아니라 오류로 판명됩니다.
오래된 데이터 / 기능에 새로운 측정 항목을 먼저 적용해야합니다

완전히 새로운 데이터를 수집하고 새로운 것을 배우려고한다면 올바른 데이터인지 알 수 없습니다. 새로운 종류의 데이터를 수집 할 때는 먼저이 데이터를 알려진 기능에 적용해야합니다. 예를 들어, 사용자 만족도에 대한 새로운 메트릭이있는 경우 최상의 기능이 만족을 돕는 데 도움이되는지 확인해야합니다. 이렇게하면 새로운 것을 배우기 위해 갈 때 검증 할 수 있습니다.

### 가설을 세우고 증거를 찾아라

일반적으로 복잡한 문제에 대한 탐색 적 데이터 분석은 반복적입니다. 데이터의 이상, 추세 또는 기타 기능을 발견 할 수 있습니다. 당연히이 데이터를 설명하기 위해 가설을 세울 것입니다. 가설을 세우고 사실이라고 선포하는 것이 중요합니다. 이 이론을 확인 / 거부 할 증거 (데이터 내부 또는 외부)를 찾으십시오. 예를 들어, 카트만두에서 다른 지형지 물이 시작되거나 휴일로 인해 이상이 있다고 생각되는 경우 해당 지형지 물이 시작된 모집단이 예외에 영향을받는 유일한 개체인지 확인하십시오. 또는 변경 규모가 출시 예상과 일치하는지 확인하십시오. 좋은 데이터 분석에는 이야기가 있습니다. 그것이 올바른 이야기인지 확인하기 위해 이야기를 스스로에게 이야기하고, 그 가설이 사실이라면 데이터에서 무엇을보아야하는지 예측 한 다음 그것이 틀렸다는 증거를 찾아야합니다. 이를 수행하는 한 가지 방법은 “내가 말하는 이야기를 검증 / 무효화하기 위해 어떤 실험을 실행해야합니까?” 이러한 실험을 수행 할 수 없거나 수행 할 수없는 경우에도 보유한 데이터로 유효성을 검사하는 방법에 대한 아이디어를 제공 할 수 있습니다.

좋은 소식은 이러한 가설과 가능한 실험으로 인해 특정 기능이나 데이터에 대해 배우려고 시도하는 새로운 질문을 할 수 있다는 것입니다. 그런 다음이 데이터를 이해하는 것이 아니라 향후 모든 종류의 분석을위한 새로운 지표와 기술을 도출 할 수 있습니다.

### 탐색적 분석은 끝에서 끝까지 지속, 반복하라 

탐색 적 분석을 수행 할 때 전체 분석을 최대한 반복하도록 노력해야합니다. 일반적으로 여러 단계의 신호 수집, 처리, 모델링 등을 수행하게됩니다. 초기 신호의 첫 단계를 완벽하게 완료하는 데 너무 오래 걸리면 동일한 시간에 더 많은 반복을 얻을 수있는 기회를 놓치게됩니다. 또한, 마지막에 마지막으로 데이터를 볼 때 방향을 바꾸는 발견을 할 수 있습니다. 그러므로, 당신의 초기 초점은 완벽에 초점을 두지 말고 모든 것을 통해 합리적인 것을 얻는 것에 초점을 두어야합니다. 분석 단계 및 분석 할 수없는 필터링 단계 및 데이터 레코드와 같은 사항은 스스로 메모하고 남겨 두십시오. 그러나 이러한 정보를 모두 제거하려는 것은 탐색 적 분석을 시작할 때 시간 낭비입니다.

# 사회적인 영역

### 데이터 분석은 데이터나 분석 기법이 아닌 질문에서 시작된다

항상 분석을해야하는 이유가 있습니다. 요구 사항을 가설 또는 가설로 공식화하는 데 시간이 걸리면 수집해야 할 데이터를 수집하고 데이터의 가능한 격차에 대해 생각하고있는 것입니다. 물론, 당신이 묻는 질문은 데이터를 볼 때 진화 할 수 있고 진화해야합니다. 그러나 의문의 여지없이 분석은 목적이 없습니다.

또한 좋아하는 기술을 찾은 다음이 기술이 작동하는 문제의 일부만 찾는 함정을 피해야합니다. 다시 한 번 질문이 무엇인지 분명하게 확인하면이를 피하는 데 도움이됩니다.

### 필터링할 때 늘 다시 확인해보고 개수를 세보아라

거의 모든 대규모 데이터 분석은 다양한 단계에서 데이터를 필터링하여 시작됩니다. 미국 사용자, 웹 검색 또는 결과 클릭으로 검색하는 것을 고려하고 싶을 수도 있습니다. 어떤 경우이든
수행중인 필터링을 인식하고 명확하게 지정
각 단계에서 필터링되는 양을 계산하십시오.
후자를 수행하는 가장 좋은 방법은 제외하고있는 모집단에 대한 모든 메트릭을 실제로 계산하는 것입니다. 그런 다음 해당 데이터를보고 ‘필터링을 통해 어떤 쿼리를 제거 했습니까?’와 같은 질문에 답변 할 수 있습니다.

또한, 필터링 대상의 예를 보는 것도 분석에 새로운 단계를 필터링하는 데 필수적입니다. 제외 할 간단한 데이터 규칙을 만들 때 실수로 ‘좋은’데이터를 쉽게 포함 할 수 있습니다.

### 비율에는 명확한 분자와 분모가 있어야한다

많은 흥미로운 지표는 기본 측정치의 비율입니다. 불행히도, 비율이 무엇인지 모호한 경우가 종종 있습니다. 예를 들어 검색 결과에서 사이트의 클릭률을 말하면 다음과 같습니다.
“# 번의 사이트 클릭 수”/‘# 해당 사이트의 결과’
‘해당 사이트에 대한 클릭 수가있는 검색 결과 페이지 # 개’/‘해당 사이트에 대한 검색 결과 페이지가 # 개 표시됨’
결과를 전달할 때 이에 대해 명확해야합니다. 그렇지 않으면 잠재 고객 (및 귀하)이 과거 결과와 비교하고 측정 항목을 올바르게 해석하는 데 어려움이 있습니다.

### 고객을 교육하라

데이터 전문가가 아닌 사람들에게 분석 및 결과를 제시하는 경우가 많습니다. 직무 중 일부는 데이터를 해석하고 결론을 도출하는 방법을 교육하는 것입니다. 이로 인해 영역에서 특정 측정이 신뢰할 수없는 이유, 인구 편향 효과를 이해하기위한 “좋은”및 “나쁜”변경에 대한 일반적인 효과 크기에 대한 신뢰 구간을 이해하는 것부터 색 영역이 실행됩니다.

데이터가 잘못 해석되거나 선택적으로 인용 될 위험이 높은 경우에 특히 중요합니다. 귀하는 소비자가 요청한 숫자뿐만 아니라 컨텍스트와 데이터의 전체 그림을 제공 할 책임이 있습니다.

### 회의론자와 챔피언

데이터를 다룰 때 얻은 통찰력의 챔피언이자 회의론자 여야합니다. 당신이 바라는 데이터에서 흥미로운 현상을 발견하게 될 것입니다. 흥미로운 현상이 발생하면“얼마나 멋진 지 보여주기 위해 어떤 다른 데이터를 수집 할 수 있습니까?” 그리고“무엇이 이것을 무효화시킬 수 있습니까?”. 특히 특정 답변을 원하는 사람 (예 : “내 기능이 훌륭합니다”)에 대해 분석을 수행하는 경우 오류를 피하기 위해 회의론자를해야합니다.

### 동료와의 공유가 우선, 외부 고객은 나중에

숙련 된 동료 검토자는 특히 소비자가 원하는 결과를 얻으므로 데이터 소비자와 질적으로 다른 피드백 및 온 전성 검사를 제공 할 수 있습니다. 이상적으로는보고있는 데이터에 대해 알고있는 동료가 있지만 일반적으로 데이터를 살펴본 경험이있는 동료라도 매우 중요합니다. 앞의 요점은 올바른 종류의 온 전성 검사 및 검증을 수행 할 수있는 몇 가지 방법을 제안했습니다. 그러나 동료와 공유하는 것은 이러한 모든 일을 스스로 수행하도록하는 가장 좋은 방법 중 하나입니다. 피어는 분석을 통해 여러 지점에서 유용합니다. 일찍부터 동료가 알고있는 문제, 측정 할 사항에 대한 제안 및이 분야의 과거 연구에 대해 알아볼 수 있습니다. 결국, 동료는 이상한 점, 불일치 또는 다른 혼란을 지적하는 데 매우 능숙합니다.

### 무지와 실수를 예상하고 받아들여라

우리가 데이터에서 배울 수있는 것에는 많은 한계가 있습니다. 네이트 실버 (Nate Silver)는 The Signal and the Noise에서 확실한 사례를 제시합니다. 확실성의 한계를 인정해야만 더 나은 예측을 할 수 있습니다. 무지를 인정하는 것은 강점이지만 일반적으로 즉시 보상되는 것은 아닙니다. 당시에는 기분이 나쁘지만 궁극적으로 데이터에 능통 한 동료 및 리더와의 존경을 얻을 수 있습니다. 실수를하고 나중에 (또는 너무 늦게) 발견하면 기분이 더 나빠지지만 실수를 사전에 소유하면 신뢰도가 높아집니다. 신뢰성은 모든 데이터 과학자에게 중요한 사회적 가치입니다.

# 끝맺으며

Top 10 List 형식의 장벽을 돌파하더라도 짧은 조언 목록을 완성 할 수는 없습니다 (수를 세지 않은 사람들을 위해 여기에 24가 있습니다). 이러한 아이디어를 실제 문제에 적용하면 도메인에서 가장 중요한 습관과 기술, 이러한 분석을 빠르고 정확하게 수행하는 데 도움이되는 도구 및 원하는 조언이이 목록에 있습니다. 배운 내용을 공유하여 더 나은 데이터 과학자가 되십시오.

이 문서에 대한 통찰력을 제공 한 모든 사람들에게 감사 드리고 싶습니다. 특히 Diane Tang, Rehan Khan, Elizabeth Tucker, Amir Najmi, Hilary Hutchinson, Joel Darnauer, Dale Neal 및 Aner Ben-Artzi.zx
