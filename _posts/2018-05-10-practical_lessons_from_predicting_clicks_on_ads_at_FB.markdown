---
layout: post
title: 광고 클릭 예측을 통해 페이스북이 얻은 실용적인 교훈
date: 2018-05-10 00:00:00
author: Facebook
categories: Data-Science
---  
  
  
**Xinran He, Junfeng Pan, Ou Jin, Tianbing Xu, Bo Liu, Tao Xu, Yanxin Shi, Antoine Atallah, Ralf Herbrich, Stuart Bowers, Joaquin Quiñonero Candela의 [*Practical Lessons from Predicting Clicks on Ads at Facebook*](http://quinonero.net/Publications/predicting-clicks-facebook.pdf)을 번역했습니다.**
  
  
- - -
  
## 초록
  
온라인 광고에서 광고주는 광고 클릭 같이 측정가능한 사용자 응답에 대해 입찰하며 대금을 지불한다. 그러므로 클릭 예측 시스템은 온라인 광고 시스템의 핵심이다. 매일 활동중인 7억 5천만명 이상의 사용자와 1백만명 이상의 유효 광고주를 고려할 때 페이스북 광고 클릭을 예측하는 일은 상당히 어려운 기계학습 작업이다. 이 논문은 결정 트리와 로지스틱 회귀를 결합한 모형을 소개하며 해당 모형은 시스템 성능에 전반적으로 큰 영향을 미치면서 결정 트리 또는 로지스틱 회귀 하나만 사용한 것보다 예측 성능을 3% 이상 향상시켰다. 다음으로 몇 개의 기본 매개 변수가 시스템 최종 예측 성능에 미치는 영향을 조사했다. 당연한 말이지만 가장 중요한 건 적절한 변수를 찾는 일이다. 사용자나 광고 이력 정보를 담은 변수는 다른 유형의 변수보다 훨씬 중요하다. 적절한 변수와 적절한 모형(의사 결정 트리 및 로지스틱 회귀)을 갖춘 다음에야 다른 요인들이 작게 기여한다(개선폭이 작더라도 규모 확장을 고려한다면 중요하다). 데이터 신선도, 학습률 스키마와 데이터 샘플링에 대해 최적 처리 방법을 적용하면 모형 성능을 다소 향상시킬 수 있으나 매우 값진 변수를 추가하거나 적절한 모형을 처음부터 선택하는 것보다 그 정도는 훨씬 못하다.
  
## 1. 개론
  
디지털 광고 업계는 수십억 달러 규모이며 매년 급격히 커지고 있다. 대부분의 온라인 광고 플랫폼에서는 광고를 동적으로 할당하며 사용자 관심도에 따라 조정한다. 사용자에 대한 광고 후보의 예상 효용을 계산하는 일에 기계학습이 중점적인 역할을 하며 이런 방식으로 시장 효율성이 높아진다.
  
Varian 또는 Edelman 등이 쓴 2007년경 논문은 Google과 Yahoo!가 개척한 클릭마다 입찰하고 지불하는 경매 시스템을 설명한다. 같은 해 Microsoft는 동일한 경매 모형을 기반으로 스폰서 검색 시장을 구축했다. 광고 입찰의 효율성은 클릭 예측의 정확도 및 보정에 달려있다. 클릭 예측 시스템은 견고하고 적응력이 있어야하며 대량의 데이터를 학습할 수 있어야한다. 본 논문의 목표는 이런 요구 사항을 염두에 두고 실제 데이터로 수행한 실험에서 얻은 통찰을 공유하는 일이다.
  
스폰서 검색 광고는 사용자 질의를 명시적 또는 암시적으로 질의와 일치하는 광고 후보를 검색하는 데 사용한다. Facebook은 광고를 검색어와 연결하진 않았지만 인구 통계 및 관심 분야로 타겟팅을 한다. 따라서 사용자가 Facebook을 방문할 경우 표시 가능한 광고의 양은 스폰서 검색보다 많을 수 있다.
  
사용자가 Facebook을 방문할 때 광고 게재가 요청되며 요청마다 매우 많은 수의 광고 후보를 처리해야 하기 때문에 먼저 연속되는 분류기를 계산 비용이 증가하는 순으로 만든다. 이 논문은 연속되는 분류기 중 마지막 단계이자 광고 최종 후보군에 대해 예측하는 클릭 예측 모형에 대해 중점적으로 설명한다.
  
결정 트리와 로지스틱 회귀를 결합한 하이브리드 모형은 그 중 하나만 사용한 것보다 예측 성능을 3% 이상 향상시킨다. 이 개선폭은 전체 시스템 성능에 중대한 영향을 미친다. 몇 개의 기본 매개 변수가 시스템 최종 예측 성능에 영향을 미친다. 예상대로 가장 중요한 건 적절한 변수를 찾는 일이다. 사용자나 광고 이력 정보를 담은 변수는 다른 유형의 변수보다 훨씬 중요하다. 적절한 변수와 적절한 모형(의사 결정 트리와 로지스틱 회귀)을 갖춘 다음에야 다른 요인들이 작게 기여한다.(개선폭이 작더라도 규모 확장을 고려한다면 중요하다). 데이터 신선도, 학습률 스키마와 데이터 샘플링에 대해 최적 처리 방법을 적용하면 모형 성능을 다소 향상시킬 수 있으나 매우 값진 변수를 추가하거나 적절한 모형을 처음부터 선택하는 것보다 그 정도는 훨씬 못하다.
  
2장은 실험 설정에 대한 개요로 시작한다. 3장에서는 여러 가지 확률론적 선형 분류기와 다양한 온라인 학습 알고리즘을 평가한다. 변수 변환과 데이터 신선도 영향을 평가하기 위해 선형 분류 관련 내용을 계속 진행할 것이다. 꽤 작은 크기의 모형을 만들면서 데이터 신선도와 온라인 학습 관련한 실제 결과에 영감을 특히 얻어 온라인 학습 계층을 통합한 모형 아키텍처를 제시할 것이다. 4장에서는 온라인 학습 계층의 핵심 구성 요소이자 실시간 훈련 데이터의 실시간 스트림을 생성시킬 수 있는 인프라 속 실험적인 부분, 즉 온라인 접합부에 대해 설명한다.
  
마지막으로 메모리와 정확도를 교환하여 시간을 계산하고 엄청난 양의 훈련 데이터를 다룰 수 있는 방법을 제시한다. 5장은 방대한 규모의 응용 프로그램이 갖고있는 메모리와 대기 시간을 유지시키는 실용적인 방법을 설명하고 6장에서는 훈련 데이터 양과 정확도 사이 균형 관계를 조사한다.
  
## 2. 실험 설정
  
엄격하고 통제된 실험을 수행하기 위해 2013년 4분기 중 한 주를 임의로 선택하여 오프라인 훈련 데이터 준비를 했다. 동일한 훈련 및 테스트 데이터를 상이한 조건에서 가져가기 위해 온라인에서 관측한 것과 비슷하게 오프라인 훈련 데이터를 준비했다. 저장한 오프라인 데이터를 훈련과 테스트 용으로 분할하여 온라인 교육과 예측을 위한 스트리밍 데이터로 시뮬레이션했다. 이 논문의 모든 실험에 동일한 교육/테스트 데이터를 테스트베드로 이용했다.
  
**평가 척도:** 기계 학습 모형에 영향을 주는 요인에 대해 가장 큰 관심이 있기에 이익과 수익에 직접 관련된 지표 대신 예측 정확도를 사용한다. 본 작업에서는 정규화 엔트로피(NE)와 정을 주요 평가 척도로 사용한다.
  
*정규화 엔트로피* 또는 보다 정확하게 정규화 크로스 엔트로피는 노출 당 평균 로그 손실을 모든 노출에 대해 백그라운드 클릭률(CTR)로 모형이 예측한 경우 평균 로그 손실이 될 값으로 나눈 것과 같다. 즉, 백그라운드 CTR의 엔트로피로 정규화한 예측 로그 손실이다. 백그라운드 CTR은 훈련 데이터셋의 관측된 평균 CTR이다. 척도를 정규화한 로그 손실이라고 보는 것이 더 이해하기 쉽다. 값이 낮을수록 모형의 예측력이 좋은 것이다. 정규화한 이유는 백그라운드 CTR이 0 또는 1에 가까울수록 로그 손실을 더 좋게 달성 할 수 있기 때문이다. 백그라운드 CTR 엔트로피로 나누면 NE는 백그라운드 CTR에 덜 민감해진다. 주어진 훈련 데이터셋이 레이블  \\(y_i \in \\{-1, +1\\}\\)과 예측 클릭 확률 \\(p_i, i = 1, 2, ... N\\)의 \\(N\\)개 샘플을 가진다고 하자. 관측된 평균 CTR이 \\(p\\)라면,

<div class="pull-right"> (1) </div>  
  
$$NE = {-{1 \over N}\sum_{i=1}^n({1+y_i \over 2} \log(p_i) + {1-y_i \over 2} \log(1 - p_i)) \over -(p * \log(p) + (1-p) * \log(1-p))}$$
  
NE는 기본적으로 상대 정보 이득(RIG) 계산에 사용하는 구성요소이며 \\(RIG = 1 - NE\\)이다.
  
*보정*은 평균 예측 CTR과 관측된 CTR 간의 비율이다. 즉, 실제로 관측된 클릭 수에 대한 예측 클릭 수 비율이다. 정확하고 잘 보정된 CTR 예측은 온라인 입찰 및 경매 성공에 필수이므로 보정은 매우 중요한 척도이다. 보정 값이 1과 다르지 않을수록 모형은 더 좋은 것이다. 실험에서는 보정값이 일반적이지 않은 경우에만 언급할 것이다.
  
보정을 고려하지 않는다면 ROC 아래 면적(AUC) 또한 순위 품질을 측정하는데 꽤 좋은 척도이다. 실제 환경에서는 잠재적인 광고 게재 미달 또는 게재 초과를 피하기 위해 최적 순서를 산출하는 것 대신 예측 자체가 정확하길 기대한다. NE는 예측 *적합도*를 측정하고 보정을 암시적으로 반영한다. 예를 들어 모형이 과대 예측을 2배로 하고 보정을 위해 전체 배율 0.5를 적용하면 AUC는 동일하지만 해당 NE는 향상된다. 측정 기준에 대한 심도있는 연구는 논문[^1]을 참조하라.

## 3. 예측 모형 구조
  
이 절은 그림 1의 묘사처럼 부스팅 결정 트리와 확률론적 희소 선형 분류기를 연결한 하이브리드 모형 구조를 제시한다. 3.1절은 의사 결정 트리가 확률론적 선형 분류기의 정확도를 상당히 향상시키는 매우 강력한 입력 변수 변환 방법임을 설명한다. 3.2절은 훈련 데이터의 신선도가 어떻게 예측의 정확도로 이어지는지 설명한다. 이를 통해 온라인 학습 방법을 선형 분류기 훈련에 적용해볼 아이디어를 얻었다. 3.3절은 확률론적 선형 분류기 두 족(族)에 대한 온라인 학습의 여러 방법을 비교한다.

![그림 1](https://aldente0630.github.io/assets/practical_lessons_from_predicting_clicks_on_ads_at_FB1.png)
  
**그림 1: 하이브리드 모형 구조. 입력 변수를 부스팅 결정 트리 통해 변환한다. 각 트리의 출력을 희소 선형 분류기에 대한 범주형 입력 변수로 처리한다. 부스팅 결정 트리가 매우 강력한 변수 변환임이 입증됐다.**
  
평가할 온라인 학습 기법은 희소 선형 분류기를 적용한 *Stochastic Gradient Descent*(SGD) 알고리즘을 기반으로 한다. 변수 변환 후 광고 노출은 구조화된 벡터 
\\(\mathbf{x} = (\mathbf{e}\_{i_1}, ..., \mathbf{e}\_{i_n})\\)의 함수로 주어진다. 여기서 \\(\mathbf{e}\_{i}\\)는 i번째 단위 벡터이고 \\(i_1, ... , i_n\\)은 n개 범주형 입력 변수의 값이다. 클릭함 또는 클릭하지 않음을 나타내는 이진 레이블 \\(y \in \\{+1, -1\\}\\)을 훈련 단계에서 갖고 있다고 가정한다.
  
광고 노출 레이블 \\((\mathbf{x}, y)\\)이 있을 때 활성 가중치 선형 조합은 다음과 같다.

<div class="pull-right"> (2) </div>
  
$$s(y, \mathbf{x}, \mathbf{w}) = y\cdot\mathbf{w}^T\mathbf{x}=y\sum_{j=1}^n{w_{j,i_{j}}},$$
  
여기서 \\(\mathbf{w}\\)는 클릭 선형 점수의 *가중치* 벡터이다.
  
논문[^2]에서 저술한대로 프로빗 회귀분석을 위한 최신 베이지안 온라인 학습 체계(BOPR)는 우도와 사전확률을 다음과 같이 정의한다.

$$p(y|\mathbf{x}, \mathbf{w}) = \Phi\left({s(y, \mathbf{x}, \mathbf{w}) \over \beta}\right), $$
  
$$p(\mathbf{w}) = \prod_{k=1}^N N(w_k;\mu_k,\sigma_k^2), $$
  
여기서 \\(\Phi(t)\\)는 표준 정규 분포의 누적 밀도 함수이고 \\(N(t)\\)는 표준 정규 분포의 밀도 함수이다.
  
적률 매칭과 함께 기대값 전파를 통해 온라인 학습을 진행한다. 가중치 벡터 \\(\mathbf{w}\\)에 대한 근사 사후 분포의 평균 및 분산으로 결과 모형은 이루어진다. BOPR 알고리즘에서 추론은 \\(p(\mathbf{w}\|y, \mathbf{x})\\)를 계산하고 가장 가깝게 분해된 \\(p(\mathbf{w})\\)의 가우시안 근사에 그것을 투영시키는 작업이다. 따라서 갱신 알고리즘은 0이 아닌 모든 성분 \\(\mathbf{x}\\)의 평균 및 분산에 관한 갱신 방정식만 가지고 표현할 수 있다(논문[^2] 참조).

<div class="pull-right"> (3) </div>
  
$$\mu_{i_j} \leftarrow \mu_{i_j} + y \cdot {\sigma^2_{i_j} \over \Sigma} \cdot v \left({s(y, \mathbf{x}, \mathbf{\mu}) \over \Sigma}\right),$$

<div class="pull-right"> (4) </div>
  
$$\sigma^2_{i_j} \leftarrow \sigma^2_{i_j} \cdot \left[1 - {\sigma^2_{i_j} \over \Sigma^2} \cdot w \left({s(y, \mathbf{x}, \mathbf{\mu}) \over \Sigma}\right)\right],$$
  
<div class="pull-right"> (5) </div>
  
$$\Sigma^2 = \beta^2 + \sum_{j=1}^n{\sigma^2_{i_j}}.$$

여기서 보정 함수 \\(v\\)와 \\(w\\)는 \\(v(t):=N(t) / \Phi(t)\\)와 \\(w(t):= v(t) \cdot \[v(t) + t]\\)로 정의한다. 이 추론을 SGD 체계 상의 신뢰 벡터 \\(\mu\\)와 \\(\sigma\\)로 볼 수 있다.
  
BOPR을 우도 함수에 대한 SGD와 비교하자면
  
$$p(y|\mathbf{x}, \mathbf{w}) = sigmoid(s(y, \mathbf{x}, \mathbf{w})),$$
  
이고 \\(sigmoid(t) = \exp(t) /(1 + \exp(t))\\)이다. 결과 알고리즘을 *로지스틱 회귀*(LR)라고 부른다. 모형 추론은 로그 우도에 대한 도함수를 계산한 다음 좌표 별 기울기 방향으로 보폭만큼 이동하면서 이루어진다.

<div class="pull-right"> (6) </div>
  
$$w_{i_j} \leftarrow w_{i_j} + y \cdot \eta_{i_j} \cdot g(s(y, \mathbf{x}, \mathbf{w})),$$
  
여기서 \\(g\\)는 0이 아닌 모든 성분의 로그 우도에 관한 기울기이고 \\(g(s) := \[y(y + 1) / 2 - y \cdot sigmoid(s)]\\)로 구할 수 있다. 식 (3)은  신뢰 불확실성 \\(\sigma\\)가 보폭 \\(\eta_{i_j}\\)을 자동으로 제어하는, (6) 같은 형태의 평균 벡터 \\(\mu\\)에 관한 좌표 별 기울기 방향으로 볼 수 있다. 3.3절에서 다양한 보폭 함수 \\(\eta\\)를 제시하고 BOPR과 비교할 것이다.
  
위에서 설명한 SGD 기반 LR과 BOPR 모두 훈련 데이터 하나 하나에 적응하는 스트림 학습기이다.

### 3.1 의사 결정 트리 변수 변환

선형 분류기의 입력 변수를 변환하여 정확도를 향상시키는 방법이 간단하게 두 가지 있다. 연속형 변수의 경우 비선형 변환을 학습하기 위한 간단한 트릭으로 변수를 구간 별로 나누고 각 구간을 범주형 변수로 처리하는 방법이 있다. 선형 분류기는 변수 구간마다 특정 상수를 대응시켜 비선형 변환을 효과적으로 학습한다. 이 때 구간 경계를 효과적으로 정하여 학습하는 것이 중요하며 그를 위한 정보 최대화 기법이 여러 개 존재한다.
  
간단하지만 효과적인 두 번째 변환 방법은 튜플 입력 변수를 만드는 것이다. 범주형 변수의 경우 완전 탐색 접근법은 모든 카테시안 곱을 취해보는 방식, 즉 원래 변수의 가능한 값 조합을 모든 값으로 갖는 새 범주형 변수를 만드는 방식이다. 모든 조합이 유용하진 않을 것이므로 그런 조합은 제거 가능하다. 입력 변수가 연속형이라면 k-d 트리 같은 것을 사용하여 공동 구간화를 시켜 만들 수 있다.
  
부스팅 결정 트리는 방금 설명한 종류의 비선형과 튜플 변환을 수행하는 강력하고 편리한 방법이다. 개별 트리는 샘플이 최종 할당되는 리프의 색인을 값으로 취하는 범주형 변수로 볼 수 있다. 이 변수 유형에 대해 1-of-K 코딩을 한다. 예를 들어 하위 트리 총 2개를 갖고 첫 번째 하위 트리가 리프 3개를, 두 번째 하위 트리가 리프 2개를 갖는 그림 1의 부스팅 트리 모형을 생각해보라. 샘플이 첫 번째 하위 트리에서 2번 리프로 끝나고 두 번째 하위 트리에서 1번 리프로 끝나는 경우 선형 분류기에 대한 전체 입력은 이진값 벡터 \\(\[0, 1, 0, 1, 0]\\)가 된다. 여기서 첫 3개의 항목은 첫 번째 하위 트리 리프에, 마지막 2개의 항목은 두 번째 하위 트리 리프에 대응한다. 부스팅 결정 트리는 전통적인 \\(L_2-TreeBoost\\) 알고리즘을 사용하는 Gradient Boosting Machine(GBM)을 적용했다. 각 학습 주기마다 이전 트리들의 잔여분을 모형화하기 위해 새로운 트리를 만든다. 부스팅 결정 트리를 실수값 벡터를 조밀한 이진값 벡터로 변환하는 지도 변수 인코딩 기법으로 이해할 수 있다. 루트 노드에서 리프 노드로의 전달은 특정 변수에 대한 규칙을 나타낸다. 이진값 벡터에 선형 분류기를 적용하는 것은 본질적으로 규칙 집합에 대한 가중치를 학습하는 것이다. 부스팅 결정 트리는 배치 방식으로 학습한다.
  
트리 변수를 선형 모형 입력으로 포함할 때 효과를 보여주기 위해 실험을 수행했다. 이 실험은 두 가지 로지스틱 회귀 모형을 비교한다. 하나는 트리 변수 변환이고 다른 하나는 일반 (변환하지 않은) 변수이다. 비교를 위해서 부스팅 결정 트리 모형만 사용했다. 표1에서 결과를 볼 수 있다.

![표 1](https://aldente0630.github.io/assets/practical_lessons_from_predicting_clicks_on_ads_at_FB2.PNG)
  
**표 1: 로지스틱 회귀(LR)과 부스팅 결정 트리(Trees)는 강력한 조합을 만든다. 그것의 정규화 엔트로피(NE)를 트리만 사용한 모형과 비교하여 측정했다.**
  
트리 변환을 하지 않은 모형 정규화 엔트로피와 비교해서 트리 변수 변환은 정규화 엔트로피를 3.4% 이상 감소시켰다. 이는 매우 중요한 개선점이다. 참고로 전형적인 피쳐 엔지니어링 실험은 비교 대상 NE의 수십여 퍼센트를 감소시킨다. LR과 Tree 모형을 단독으로 사용하면 비슷한 예측 정확도(LR이 조금 더 좋음)를 갖지만 조합하면 정확도가 크게 향상한다는 점이 흥미롭다. 예측 정확도 향상은 중요합니다. 참고로 피쳐 엔지니어링 실험의 대부분은 Normalized Entropy를 백분율로 감소시킵니다.

### 3.2 데이터 신선도

(번역 중)
  
[^1]: J. Yi, Y. Chen, J. Li, S. Sett, and T. W. Yan. Predictive model performance: Offline and online evaluations. In KDD, pages 1294–1302, 2013.
[^2]: T. Graepel, J. Quiñonero Candela, T. Borchert, and R. Herbrich. Web-scale bayesian click-through rate prediction for sponsored search advertising in Microsoft’s Bing search engine. In ICML, pages 13–20, 2010.
