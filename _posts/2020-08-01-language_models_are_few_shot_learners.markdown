---
layout: post
title: OpenAI GPT-3: 언어 모델은 퓨-샷 학습자이다
date: 2020-08-01 00:00:00
author: Soheil Tehranipour
categories: Data-Science
---  
  
  
**Soheil Tehranipour의 [*OpenAI GPT-3: Language Models are Few-Shot Learners*](https://medium.com/analytics-vidhya/openai-gpt-3-language-models-are-few-shot-learners-82531b3d3122)을 번역했습니다.**
  
  
- - -

[OpenAI](https://openai.com)는 최근 자연어 처리를 위한 심층 학습 ㅁ 인 GPT-3을 설명하는 논문을 발표했다. GPT-2는 이전 버전 인 GPT-2보다 100 배 더 많은 175 억 개의 매개 변수 (!!!)를 가지고있다. 이 모델은 거의 5 조 단어로 사전 교육을 받았으며 미세 조정없이 여러 NLP 벤치 마크에서 SOTA 성능을 달성했습니다.
 
