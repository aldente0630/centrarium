---
layout:     post
title:      Using Machine Learning to Predict Value of Homes on Airbnb
date:       2018-04-16 00:00:00
author:     Robert Chang
categories: Data-Science
---  
  
  
**Robert Chang의 [*Using Machine Learning to Predict Value of Homes on Airbnb*](https://medium.com/airbnb-engineering/using-machine-learning-to-predict-value-of-homes-on-airbnb-9272d3d4739d)을 번역했습니다.**
  
  
- - -
  
## 서론
  
데이터 제품은 항상 Airbnb 서비스의 중요한 부분이다. 그러나 우리는 오랫동안 데이터 제품를 만드는데 비용이 많이 든다는 사실을 인지해왔다. 예를 들어 개인화 검색 순위는 게스트가 집을 더 쉽게 찾도록 도와주며 스마트 가격 정책은 호스트가 수요와 공급에 따라 더 경쟁력있는 가격을 설정할 수 있게끔 도와준다. 그러나 이 프로젝트들은 각각 데이터 과학과 공학만을 위한 시간 및 노력을 필요로 했다.
  
최근 Airbnb 기계 학습 인프라의 발전으로 새로운 기계 학습 모형을 제품으로 배포하는 비용이 크게 절감되었다. 예를 들어 ML Infra팀은 고품질의, 검증되고, 재사용 가능한 변수들을 사용자가 모형에 활용할 수 있게 범용 변수 저장소를 구축했다. 데이터 과학자는 여러 AutoML 도구를 작업 흐름에 통합시켜 모형 선택 및 성능 벤치마크를 가속화했다. 또한 ML Infra팀은 Jupyter 노트북을 Airflow 파이프라인으로 변환하는 새로운 프레임워크를 만들었다.
  
이 문서에서는 LTV 모델링, 즉, Airbnb에 올라온 집 가치를 예측하는 특정 활용 사례를 통해 이런 도구들이 어떻게 함께 동작하며 모델링 절차를 빠르게 하고 전체적인 개발 비용을 낮추는지 설명하겠다.
    
## LTV란 무엇인가?
  
전자 상거래 및 마켓플레이스 기업에서 인기있는 개념인 고객 생애 가치(LTV)는 사용자 당 고정 시간 동안 발생할 추정 가치를 뜻하며 대개 달러 단위로 측정된다.
  
Spotify와 Netflix 등 전자 상거래 회사는 LTV를 구독료 설정 등 가격 결정에 자주 사용한다. Airbnb 같은 마켓플레이스 기업에서 사용자 LTV를 알면 다양한 마케팅 채널에 예산을 효율적으로 할당하고 키워드 기반 온라인 마케팅에 대해 보다 정확한 입찰 가격을 계산하고 숙소 세그먼트를 더 잘 만들 수 있다.
  
과거 데이터를 사용해서 기존 숙소 [과거 가치를 계산](https://medium.com/swlh/diligence-at-social-capital-part-3-cohorts-and-revenue-ltv-ab65a07464e1)할 수 있지만 새 숙소 LTV를 예측하기 위해 기계 학습을 사용하여 한 걸음 더 나아갔다.
  
## LTV 모델링을 위한 기계학습 작업 흐름
  
데이터 과학자는 일반적으로 피쳐 엔지니어링, 프로토타이핑 및 모형 선택 같은 기계학습 관련 작업에 익숙하다. 그러나 모형 프로토타입을 제품으로 사용하려면 종종 데이터 과학자가 익숙하지 않은 데이터 엔지니어링 기술의 직교 집합이 필요하다.
  
![](https://aldente0630.github.io/assets/using_machine_learning_to_predict_value_of_homes_on_airbnb1.png)
  
다행히 Airbnb에는 ML 모형 제품화 뒷편으로 엔지니어링 작업을 일반화시켜주는 기계 학습 도구가 있다. 사실 이런 놀라운 도구가 없었다면 모형을 제품화하기 어려웠을거다. 게시물 나머지 부분에서 각 과제를 해결하는데 사용한 도구를 함께 제시할 것이며 네 가지 주제를 다룰 것이다.
  
* **피쳐 엔지니어링:** 관계있는 변수를 정의
* **프로토타이핑과 훈련:** 모형 프로토타입을 훈련
* **모형 선택과 평가:** 모형을 선택하고 조정
* **제품화:** 선택한 모형 프로토타입을 제품으로 바꿈
  
## 피쳐 엔지니어링
>*사용한 도구: Airbnb 내부 변수 저장소 — Zipline*
  
지도 기계 학습 프로젝트 첫 번째 단계 중 하나는 선택한 결과 변수와 상관성이 있을 관련 변수들을 정의하는 것이다. 이 과정을 피쳐 엔지니어링이라고한다. 예를 들어 LTV 예측할 때 숙소를 이용할 수 있는 다음 180 달력일 내 비율 또는 동일한 시장에서 비교가능한 숙소 대비 숙소의 가격을 계산할 수 있다.
  
Airbnb에서 피쳐 엔지니어링은 종종 Hive 쿼리를 작성하여 처음부터 변수 만드는 걸 의미한다. 그러나 특정 도메인 지식과 비즈니스 로직이 필요하기 때문에 이 작업은 지루하고 시간이 오래 걸린다. 따라서 변수 파이프라인은 쉽게 공유하거나 재사용할 수 없는 경우가 많다. 이 작업을 보다 확장 가능하게 하기 위해 우리는 호스트, 게스트, 숙소 또는 시장 수준과 같이 다양한 세분화 수준에서 변수를 제공하는 훈련용 변수 저장소 Zipline을 개발했다.
  
이 내부 도구의 크라우드소스적 특징으로 인해 데이터 과학자는 다른 사람들이 과거 프로젝트에서 준비했던 다양한, 고품질의, 검증된 변수들을 사용할 수 있다. 원하는 변수를 사용할 수 없는 경우 사용자는 다음과 같은 변수 구성 파일을 이용하여 자신만의 변수를 만들 수 있다.
  
 ```{.json}
source: {
  type: hive
  query:"""
    SELECT
        id_listing as listing
      , dim_city as city
      , dim_country as country
      , dim_is_active as is_active
      , CONCAT(ds, '23:59:59.999') as ts
    FROM
      core_data.dim_listings
    WHERE
      ds BETWEEN '{{ start_date }}' AND '{{ end_date }}'
  """
  dependencies: [core_data.dim_listings]
  is_snapshot: true
  start_date: 2010-01-01
}
features: {
  city: "City in which the listing is located."
  country: "Country in which the listing is located."
  is_active: "If the listing is active as of the date partition."
}
 ```
  
훈련 데이터를 구성하는데 여러 변수가 필요한 경우 Zipline은 지능형 key join을 자동으로 수행하고 뒤편에서 훈련 데이터를 채워넣는다. 숙소 LTV 모형을 위해 기존 Zipline 변수를 사용했고 나만의 변수를 일부 추가했다. 결론적으로 모형에 다음을 포함한 변수 150개 이상이 사용되었다.
  
* **장소:** 국가, 시장, 이웃과 다양한 지리학 변수
* **가격:** 야간 요금, 청소비, 유사한 숙소 대비 가격 포인트
* **이용가능성:** 숙박 가능한 총 일수, 직접 예약 막아놨던 일수 백분율
* **예약가능성:** 예약 횟수 또는 지난 X일간 예약되었던 날 수
* **품질:** 리뷰 점수, 리뷰 개수와 어메니티

![훈련 데이터 예시](https://aldente0630.github.io/assets/using_machine_learning_to_predict_value_of_homes_on_airbnb2.png)
  
예측 변수와 결과 변수가 정의되면 과거 데이터로부터 학습하게끔 모형 훈련을 시작해볼 수 있다.
  
## 프로토타이핑과 훈련
>*사용한 도구: Python 기계학습 라이브러리 — [scikit-learn](http://scikit-learn.org/stable/)*

위의 교육 데이터 세트 예제에서와 같이 모델에 적합하기 전에 추가 데이터 처리를 수행해야하는 경우가 있습니다. 

데이터 대체 : 누락 된 데이터가 있는지, 그리고 데이터가 무작위로 누락되었는지 확인해야합니다. 그렇지 않은 경우 왜 그 원인을 조사하고 근본 원인을 이해해야합니다. 그렇다면 누락 된 값을 대신해야합니다.

범주 형 변수 인코딩 : 모델에서 문자열에 맞추는 방법을 모르기 때문에 종종 모델에서 원시 범주를 사용할 수 없습니다. 카테고리 수가 적 으면 one-hot 인코딩 사용을 고려할 수 있습니다. 그러나 카디널리티가 높으면 서수 인코딩을 사용하여 각 카테고리의 빈도 수를 인코딩하는 것이 좋습니다.

이 단계에서는 사용할 기능 중 무엇이 가장 적합한 지 모르기 때문에 신속하게 반복 할 수있는 코드를 작성하는 것이 중요합니다. Scikit-Learn 및 Spark와 같은 오픈 소스 도구에서 일반적으로 사용할 수있는 파이프 라인 구조는 프로토 타이핑을위한 매우 편리한 도구입니다. 파이프 라인을 사용하여 데이터 과학자는 기능을 변형해야하는 방법과 훈련 할 모델을 설명하는 고급 청사진을 지정할 수 있습니다. 좀 더 구체적으로하기 위해 LTV 모델 파이프 라인의 코드 스 니펫이 있습니다.

```{.python}
transforms = []

transforms.append(
    ('select_binary', ColumnSelector(features=binary))
)

transforms.append(
    ('numeric', ExtendedPipeline([
        ('select', ColumnSelector(features=numeric)),
        ('impute', Imputer(missing_values='NaN', strategy='mean', axis=0)),
    ]))
)

for field in categorical:
    transforms.append(
        (field, ExtendedPipeline([
            ('select', ColumnSelector(features=[field])),
            ('encode', OrdinalEncoder(min_support=10))
            ])
        )
    )
    
features = FeatureUnion(transforms)
```

높은 수준에서 우리는 파이프 라인을 사용하여 유형이 바이너리, 범주 또는 숫자인지 여부에 따라 다양한 유형의 기능에 대한 데이터 변환을 지정합니다. FeatureUnion은 기능을 열 단위로 결합하여 최종 교육 데이터 세트를 작성합니다.

프로토 타입을 파이프 라인으로 작성하면 데이터 변환을 사용하여 지루한 데이터 변환을 추상화 할 수 있다는 이점이 있습니다. 집합 적으로 이러한 변환을 통해 교육 및 평가 과정에서 일관되게 데이터가 변형되므로 프로토 타입을 프로덕션으로 변환 할 때 데이터 변환의 공통적 인 문제를 해결할 수 있습니다.

또한 파이프 라인은 모델 변환에서 데이터 변환을 분리합니다. 위의 코드에 나와 있지 않지만 데이터 과학자는 모델 피팅 추정을 지정하는 마지막 단계를 추가 할 수 있습니다. 다른 평가자를 탐구함으로써 데이터 과학자는 모델 선택 오류를 개선하기 위해 최상의 모델을 선택하기 위해 모델 선택을 수행 할 수 있습니다.

## 모형 선택 수행
>*사용한 도구: 다양한 AutoML 프레임워크 

이전 섹션에서 언급했듯이 우리는 어떤 후보 모델이 생산에 가장 적합한 지 결정해야합니다. 이러한 결정을 내리기 위해서는 모델 해석 가능성과 모델 복잡성 간의 절충점을 고려해야합니다. 예를 들어, 희소 선형 모델은 해석하기 쉽지만 일반화하기에 충분히 복잡하지는 않습니다. 트리 기반 모델은 비선형 패턴을 캡처 할만큼 충분히 유연하지만 해석하기는 어렵습니다. 이를 바이어스 - 분산 (Bias-Variance) 절충이라고합니다.

보험 또는 신용 심사와 같은 응용 프로그램에서 모델은 의도적으로 특정 고객을 차별하는 것을 피하는 것이 중요하기 때문에 모델을 해석 할 수 있어야합니다. 그러나 이미지 분류와 같은 응용 프로그램에서는 해석 가능한 모델보다 성능 분류자를 갖는 것이 훨씬 더 중요합니다.

모델 선택에 많은 시간이 소요될 수 있으므로 다양한 AutoML 도구를 사용하여 프로세스 속도를 향상시키는 방법을 실험했습니다. 다양한 모델을 탐색하여 어떤 유형의 모델이 가장 잘 수행되는 경향이 있는지 발견했습니다. 예를 들어, eXtreme 그라디언트 부스트 트리 (XGBoost)는 평균 응답 모델, 능선 회귀 모델 및 단일 의사 결정 트리와 같은 벤치 마크 모델보다 월등히 뛰어나다는 것을 알게되었습니다.

우리의 주요 목표는 상장 가치를 예측하는 것이었기 때문에 XGBoost를 사용하여 최종 모델을 쉽게 생산할 수 있었고 해석 가능성에 대한 유연성을 선호했습니다.

## 모형 선택 수행
>*사용한 도구: 다양한 AutoML 프레임워크 

이전에 언급했듯이 생산 파이프 라인을 구축하는 것은 로컬 랩톱에서 프로토 타입을 제작하는 것과 상당히 다릅니다. 예를 들어 정기적 인 재교육을 어떻게 수행 할 수 있습니까? 얼마나 많은 수의 예제를 효율적으로 채점합니까? 우리는 시간이 지남에 따라 모델 성능을 모니터링하는 파이프 라인을 어떻게 구축합니까?

Airbnb에서 우리는 Jupyter 노트북을 Airflow 기계 학습 파이프 라인으로 자동 변환하는 ML Automator라는 프레임 워크를 구축했습니다. 이 프레임 워크는 이미 Python으로 프로토 타입을 작성하는 데 익숙한 데이터 과학자를 위해 특별히 설계되었으며 제한된 데이터 엔지니어링 경험을 바탕으로 자신의 모델을 프로덕션으로 가져 가고자합니다.

첫째, 프레임 워크는 사용자가 노트북에 모델 구성을 지정해야합니다. 이 모델 구성의 목적은 프레임 워크에 교육 테이블의 위치, 교육을 위해 할당 할 계산 리소스의 수 및 점수 계산 방법을 알려주는 것입니다.

또한 데이터 과학자는 특정 적합성 및 변형 기능을 작성해야합니다. fit 함수는 학습이 정확하게 수행되는 방법을 지정하며, 변환 함수는 분산 스코어링을위한 Python UDF로 래핑됩니다 (필요한 경우).

다음은 LTV 모델에서 적합 함수 및 변형 함수가 정의되는 방법을 보여주는 코드 스 니펫입니다. fit 함수는 프레임 워크에 XGBoost 모델이 훈련되고 이전에 정의한 파이프 라인에 따라 데이터 변환이 수행된다는 사실을 알려줍니다.

노트북이 병합되면 ML Automator는 숙련 된 모델을 Python UDF로 래핑하고 아래의 것과 같은 Airflow 파이프 라인을 만듭니다. 데이터 직렬화, 주기적 재 학습 스케줄링 및 분산 스코어링과 같은 데이터 엔지니어링 작업은 모두이 일괄 처리 작업의 일부로 캡슐화됩니다. 결과적으로이 프레임 워크는 데이터 과학자와 함께 모델을 생산에 투입하는 전담 데이터 엔지니어가있는 것처럼 데이터 과학자를위한 모델 개발 비용을 크게 절감합니다!
